{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syulimo/3rd-ML100Days/blob/master/Lecture_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPI3PfATxAFa"
      },
      "source": [
        "# Data Modeling\n",
        "\n",
        "The goal of this workshop is to understand how to develop models to accurately predict target variables of a sample dataset. We'll also discuss how to analyze model performance.\n",
        "\n",
        "## Content\n",
        "\n",
        "1. Preparing Data\n",
        "- Standardization\n",
        "- Train-Test Split\n",
        "2. Binary Classification\n",
        "- Logistic Regression\n",
        "3. Metrics to Assess Performance\n",
        "- Confusion Matrix\n",
        "- Precision & Recall\n",
        "- F-1 Score\n",
        "4. More Binary Classification Methods\n",
        "- Support Vector Machine\n",
        "- Decision Tree\n",
        "- Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ssmbq7LxAFe"
      },
      "source": [
        "# Section 0: Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roUF5KZ6xAFf"
      },
      "source": [
        "### **Q0.1** Import pandas, numpy, and scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxNOHrqFxAFg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWQcVcpHxAFh"
      },
      "source": [
        "### **Q0.2** Import \"stroke_prediction_2.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('stroke_prediction_2.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "x68055iBrm1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Stroke Incidence: \", df.sum(axis=0)['stroke']/df.shape[0]*100, \"%\")"
      ],
      "metadata": {
        "id": "Hg7k8KFbXpkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdlCJ1OGsxYl"
      },
      "source": [
        "### **Q0.3** Prepare \"stroke_prediction_2.csv\" via one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], drop_first=True)"
      ],
      "metadata": {
        "id": "zvS69_lrtMi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaohruJdwHCF"
      },
      "source": [
        "### **Q0.4** Split dataset into X and y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['stroke']\n",
        "X = df.drop(target+['id'], axis=1)\n",
        "y = df[target].values.ravel()"
      ],
      "metadata": {
        "id": "3bSViOdsv7rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJPjHzQ409yk"
      },
      "source": [
        "# Section 1: Preprocess and Standardize Data\n",
        "Using ```sklearn```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "PQdNsRgX0aXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X: {X.shape}   |    y: {y.shape}\")"
      ],
      "metadata": {
        "id": "R78GNHZUyv2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q1.1** Train-test split the data"
      ],
      "metadata": {
        "id": "bIh-TIcvlKzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "3CVyF4kzvpTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test:  X: {X_test.shape}    |    y: {y_test.shape}\")\n",
        "print(f\"Train: X: {X_train.shape}   |    y: {y_train.shape}\")"
      ],
      "metadata": {
        "id": "fuWniUiqyoUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q1.2** Standardize the training data, and apply the same fit to the test data"
      ],
      "metadata": {
        "id": "vCeMcKMqlPEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "EElIVl-t1Ith"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMEwolKAzy6k"
      },
      "source": [
        "# Section 2: Implement Logistic Regression Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q2.1** Build LR Model and generate a prediction based on test data\n",
        "\n"
      ],
      "metadata": {
        "id": "ukHQZPDIEOHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "HCuOz1Po089_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "Wr7C-SaM05ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q2.2** Determine Accuracy of LR model"
      ],
      "metadata": {
        "id": "ssV3GVvxER70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "6UrSMKVP2N-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "hD39_n6H2PwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q2.3** Assemble confusion matrix for LR model performance"
      ],
      "metadata": {
        "id": "hmCm0iWeEVXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "UiZyP_NhE1fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(f' TP: {tp}    FP: {fp}\\n FN: {fn}    TN: {tn}')"
      ],
      "metadata": {
        "id": "4M3Ls97LDtOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsWrsCBqxAFq"
      },
      "source": [
        "### **Q2.4:** Compute the Precision, Recall, and F1 Score of our Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# type your answer here"
      ],
      "metadata": {
        "id": "IbGjNVgFi8Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q2.5** Obtain the weights (coefficients) of the LR model"
      ],
      "metadata": {
        "id": "w1YSt7apLZiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_coef = pd.DataFrame({\"weight\": model.coef_[0]})\n",
        "lr_coef[\"coef\"] = X.columns\n",
        "lr_coef = lr_coef[[\"coef\", \"weight\"]]\n",
        "lr_coef.sort_values(by=\"weight\", ascending=False)"
      ],
      "metadata": {
        "id": "rlBjAzueLS3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XB8anZBkn6m"
      },
      "source": [
        "# Section 3: Implement a Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q3.1** Build SVM Model (SVC) and generate a prediction based on test data"
      ],
      "metadata": {
        "id": "Ix6ckgdEmBd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "6s50xZazmBd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type your answer here"
      ],
      "metadata": {
        "id": "jzAedyXntgLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the same analysis as before"
      ],
      "metadata": {
        "id": "4D2Mrv5lmBd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7XWllh8x1aC"
      },
      "source": [
        "# Section 4: Implement a Decision Tree Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q4.1** Build a decision tree model generate a prediction based on test data"
      ],
      "metadata": {
        "id": "xcke0A-0x3QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "kqfZxCYyx3QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type your answer here"
      ],
      "metadata": {
        "id": "otUng2ttx3QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the same analysis as before"
      ],
      "metadata": {
        "id": "NofAYwwbx3QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q4.2** Visualize the decision tree"
      ],
      "metadata": {
        "id": "y7NwOIQ16wcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_model, filled=True, feature_names=X.columns, class_names=['No Stroke', 'Stroke'])\n",
        "plt.title(\"Decision Tree for Stroke Prediction\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3nqLIW_MzkPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21azoEK367fF"
      },
      "source": [
        "# Section 5: Implement a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q5.1** Build a decision tree model generate a prediction based on test data"
      ],
      "metadata": {
        "id": "OrAnTJ-l67fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "YxvUjzXD67fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type your answer here"
      ],
      "metadata": {
        "id": "Rt9Yrf6g67fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the same analysis as before"
      ],
      "metadata": {
        "id": "SGQd4sA367fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**That wraps up DEEP Lecture #3!**\n",
        "\n",
        "See you next week where you'll be able to apply the techniques discussed in today's workshop to your team's dataset!"
      ],
      "metadata": {
        "id": "fOFS1ysn-n9C"
      }
    }
  ]
}